要求低时间延迟的数据访问的应用不适合运行在HDFS上，例如几十毫秒的范围。
目前对于低延迟的访问需求，HBase是更好的选择。

每个文件大约需要150字节的存储空间，那么100万个文件，占多少空间呢？300M？

HDFS中的文件不支持有多个写入者的操作，也不支持在文件的任意位置进行修改。

HDFS也有block的概念，默认是64M。HDFS中小于一个块大小的文件不会占据整个块的空间。
64M的大的块定义，为了最小化寻址的开销。这样，时间的消耗主要在数据传输上。很多情况下，HDFS使用128M大小的块定义。
块也不能设置的过大，因为MapReduce中的Map任务通常一次处理一个块中的数据，如果任务数太少的话，处理速度就会变慢。

任何一台节点上都可以运行HDFS命令.各个节点的HADOOP拷贝时一样的.配置好一个后,可以用SCP,SVN,GIT等工具进行分发.

启动的时候貌似只要启动namenode之后，其他节点会自动启动。

气象数据的下载地址
ftp://ftp3.ncdc.noaa.gov/pub/data/noaa/